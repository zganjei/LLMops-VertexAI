{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zganjei/LLMops-VertexAI/blob/main/llmops_vertexai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlFL6f1JqNAS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install google-cloud-aiplatform\n",
        "!pip install kfp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load credentials and relevant Python libraries\n",
        "NOTE : create a project on GCP and use its name below, in the PROJECT_ID variable"
      ],
      "metadata": {
        "id": "jbnbMHP-qQcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.cloud.aiplatform as aiplatform\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "\n",
        "auth.authenticate_user()\n",
        "# Verify the current credentials being used\n",
        "credentials, project = default()\n",
        "print(project)\n",
        "\n",
        "PROJECT_ID = \"zeinab-llmops-vertexai-452213\"\n",
        "REGION = \"us-central1\"\n",
        "\n"
      ],
      "metadata": {
        "id": "UEbI9IyHql_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e1ee1b-c819-45fb-9e1d-8ea886970b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's import and initialize VertexAI SDK to be able to interact with VertexAI servers in the cloud"
      ],
      "metadata": {
        "id": "FdhXLorBs4Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)"
      ],
      "metadata": {
        "id": "kedc8FuPqyKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm going to initialize and use BigQuery data warehouse which is Serverless (so I don't need to manage servers), plus, it uses SQL. SQL is efficient for processing large amounts of data, and is very good for data cleaning and data preparation. Pandas is more used when we have the data locally. SQL is better when data is stored in a data warehouse.\n",
        "\n",
        "For this project I use StackOverflow public dataset :)\n",
        "This dataset contains tables for questions, answers, and metadata."
      ],
      "metadata": {
        "id": "31XJjz8ataKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "print(f\"Credentials: {credentials}, Bigquery client initialized for Project: {bq_client.project}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrNkJSYwuFza",
        "outputId": "95fdf730-95c7-44c6-f6b3-12eba5eb4c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Credentials: <google.auth.compute_engine.credentials.Credentials object at 0x7b6da911b650>, Bigquery client initialized for Project: zeinab-llmops-vertexai-452213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's enable Vertex AI API, Gemini, and cloud storage"
      ],
      "metadata": {
        "id": "6ZLpeZ-iBCbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !gcloud projects list\n",
        "# !gcloud projects get-iam-policy zeinab-llmops-vertexai-452213\n",
        "# refresh authentication in Colab\n",
        "# !gcloud auth application-default login\n",
        "# !gcloud auth application-default set-quota-project zeinab-llmops-vertexai-452213\n",
        "# !gcloud services enable --project zeinab-llmops-vertexai-452213 aiplatform.googleapis.com #enable vertex ai\n",
        "# !gcloud services enable --project zeinab-llmops-vertexai-452213 generativelanguage.googleapis.com #enable gemini\n",
        "# !gcloud services enable --project zeinab-llmops-vertexai-452213 storage.googleapis.com\n",
        "\n",
        "!gcloud services list --project zeinab-llmops-vertexai-452213 --enabled | grep -E 'aiplatform|generativelanguage|storage'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztrz1tC8z3zt",
        "outputId": "a1f2501a-d9e0-4501-8ee0-d2e69d4f0b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aiplatform.googleapis.com           Vertex AI API\n",
            "bigquerystorage.googleapis.com      BigQuery Storage API\n",
            "generativelanguage.googleapis.com   Generative Language API\n",
            "storage-component.googleapis.com    Cloud Storage\n",
            "storage.googleapis.com              Cloud Storage API\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's explore the data and see what tables are there in StackOverflow dataset."
      ],
      "metadata": {
        "id": "AssIsBoiu6ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "QUERY_TABLES = \"\"\"\n",
        "SELECT\n",
        "  table_name\n",
        "FROM\n",
        "  `bigquery-public-data.stackoverflow.INFORMATION_SCHEMA.TABLES`\n",
        "\"\"\"\n",
        "print(QUERY_TABLES)\n",
        "query_job = bq_client.query(QUERY_TABLES)\n",
        "for row in query_job:\n",
        "  for value in row.values():\n",
        "    print(value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vtQbkpfuwRa",
        "outputId": "f1dfd9aa-2d94-4a18-e040-314829d74b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SELECT\n",
            "  table_name\n",
            "FROM\n",
            "  `bigquery-public-data.stackoverflow.INFORMATION_SCHEMA.TABLES`\n",
            "\n",
            "posts_answers\n",
            "users\n",
            "posts_orphaned_tag_wiki\n",
            "posts_tag_wiki\n",
            "stackoverflow_posts\n",
            "posts_questions\n",
            "comments\n",
            "posts_tag_wiki_excerpt\n",
            "posts_wiki_placeholder\n",
            "posts_privilege_wiki\n",
            "post_history\n",
            "badges\n",
            "post_links\n",
            "tags\n",
            "votes\n",
            "posts_moderator_nomination\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Query optimization and joining tables\n",
        "We want to do parameter-efficient fine-tuning. Since the data is too big, we export the result of join of python questions and answers into a cloud storage bucket. This enables us to access data quickly."
      ],
      "metadata": {
        "id": "ybCx1pzsCWOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QUERY = \"\"\"\n",
        "SELECT\n",
        "  CONCAT(q.title,q.body) AS input_text,\n",
        "  a.body AS output_text\n",
        "FROM\n",
        "  `bigquery-public-data.stackoverflow.posts_questions` q\n",
        "JOIN\n",
        "  `bigquery-public-data.stackoverflow.posts_answers` a\n",
        "ON\n",
        "  q.accepted_answer_id = a.id\n",
        "WHERE\n",
        "  q.accepted_answer_id IS NOT NULL AND\n",
        "  REGEXP_CONTAINS(q.tags, \"python\") AND\n",
        "  a.creation_date >= \"2022-01-01\"\n",
        "LIMIT\n",
        "  10000\n",
        "\"\"\"\n",
        "\n",
        "query_job = bq_client.query(QUERY)\n"
      ],
      "metadata": {
        "id": "vRL4tvkmwHgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's set the format of the data to be easy for pandas to read."
      ],
      "metadata": {
        "id": "q6jsaF58C3EJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "  stack_overflow_df = query_job\\\n",
        "    .result()\\\n",
        "    .to_arrow()\\\n",
        "    .to_pandas()\n",
        "except Exception as e:\n",
        "  print('The DataFrame to loo large to load into memory.',e)\n",
        "stack_overflow_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oDku81q9C6pC",
        "outputId": "0e0d6d12-9784-4975-8bda-6ac756b5d7c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          input_text  \\\n",
              "0  Using nbconvert to hide all input cells?<p>I h...   \n",
              "1  How to multiply each digit of an array in the ...   \n",
              "2  How to get the text of the message to which th...   \n",
              "3  How to append datafrarme columns in list?<p>I ...   \n",
              "4  How to create a custom timerange and convert i...   \n",
              "\n",
              "                                         output_text  \n",
              "0  <p>You can pass the argument <code>--no-input<...  \n",
              "1  <p>if you want a simple solution, use numpy:</...  \n",
              "2  <p>Yes, <a href=\"https://discordpy.readthedocs...  \n",
              "3  <p>Use <a href=\"http://pandas.pydata.org/panda...  \n",
              "4  <p>You could use <code>strftime</code>:</p>\\n<...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7af1802-b3d0-412c-b76b-5d6e64eeeb8a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_text</th>\n",
              "      <th>output_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Using nbconvert to hide all input cells?&lt;p&gt;I h...</td>\n",
              "      <td>&lt;p&gt;You can pass the argument &lt;code&gt;--no-input&lt;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How to multiply each digit of an array in the ...</td>\n",
              "      <td>&lt;p&gt;if you want a simple solution, use numpy:&lt;/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How to get the text of the message to which th...</td>\n",
              "      <td>&lt;p&gt;Yes, &lt;a href=\"https://discordpy.readthedocs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How to append datafrarme columns in list?&lt;p&gt;I ...</td>\n",
              "      <td>&lt;p&gt;Use &lt;a href=\"http://pandas.pydata.org/panda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How to create a custom timerange and convert i...</td>\n",
              "      <td>&lt;p&gt;You could use &lt;code&gt;strftime&lt;/code&gt;:&lt;/p&gt;\\n&lt;...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7af1802-b3d0-412c-b76b-5d6e64eeeb8a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d7af1802-b3d0-412c-b76b-5d6e64eeeb8a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d7af1802-b3d0-412c-b76b-5d6e64eeeb8a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4edf9276-ba96-4eec-91e8-b1140ca1bb3a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4edf9276-ba96-4eec-91e8-b1140ca1bb3a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4edf9276-ba96-4eec-91e8-b1140ca1bb3a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stack_overflow_df",
              "summary": "{\n  \"name\": \"stack_overflow_df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"input_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"why my code doesnt work? i need to make a password generator,<p>when i chose 2 letters, 2 symbols and two numbers it works, but when i chose per example 40 numbers, 40 sybmols and 40 numbers, it doesnt work, say that</p>\\n<p>when i chose 2 letters, 2 symbols and two numbers it works, but each number dont work</p>\\n<p>say that:</p>\\n<p>Traceback (most recent call last):\\nFile &quot;main.py&quot;, line 866, in \\nsymbols_password += symbols[random.randint(0,len(symbols))]\\nIndexError: list index out of range</p>\\n<p>it says that\\nthis line is line isnt on the range\\nletters[random.randint(0,len(letters))]</p>\\n<p>my code</p>\\n<pre><code>import random\\nletters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\\nnumbers = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\\nsymbols = ['!', '#', '$', '%', '&amp;', '(', ')', '*', '+']\\n\\nprint(&quot;Welcome to the PyPassword Generator!&quot;)\\nnr_letters= int(input(&quot;How many letters would you like in your password?\\\\n&quot;)) \\nnr_symbols = int(input(f&quot;How many symbols would you like?\\\\n&quot;))\\nnr_numbers = int(input(f&quot;How many numbers would you like?\\\\n&quot;))\\n\\nletters_password = &quot;&quot;\\nsymbols_password = &quot;&quot;\\nnumber_password = &quot;&quot;\\n\\nif int(nr_letters) &lt;= 50 and int(nr_symbols) &lt;= 50 and int(nr_numbers) &lt;= 50:\\n for generator_letters in range(0,int(nr_letters)):\\n   letters_password += letters[random.randint(0,len(letters))]\\n \\n for generator_symbols in range(0,int(nr_symbols)):\\n   symbols_password += symbols[random.randint(0,len(symbols))]\\n  \\n for generator_numbers in range(0,int(nr_numbers)):\\n   number_password += numbers[random.randint(0,len(numbers))]\\n\\nelse:\\n  if nr_letters &gt; 50 and nr_symbols &gt; 50 and nr_numbers &gt; 50:\\n    print(&quot;you chose too many letters,symbols and numbers.\\\\n The maximum is 50 of each&quot;)\\n  elif nr_letters &gt; 50 and nr_symbols &gt; 50  :\\n    print(&quot;you chose too many letters and symbols.\\\\n The maximun us 50 of each&quot;)\\n  elif nr_letters &gt; 50 and nr_numbers &gt; 50: \\n    print(&quot;you chose too many letters and numbers.\\\\n The maximun us 50 of each&quot;)\\n  elif nr_symbols &gt; 50 and nr_numbers &gt; 50:\\n    print(&quot;you chose too many symbols and numbers.\\\\n The maximun us 50 of each&quot;)\\n  elif nr_numbers &gt; 50:\\n    print(&quot;you chose too many numbers, the maximum is 50&quot;)\\n  elif nr_letters &gt; 50:    \\n    print(&quot;you chose too many letters, the maximum is 50&quot;)\\n  elif nr_symbols &gt; 50:\\n   print(&quot;you chose too many smybols, the maximum is 50&quot;)\\n\\n\\n\\npassword =(str(letters_password)+ str(symbols_password) + str(number_password))\\n  \\nprint(password)\\n</code></pre>\",\n          \"Top2Vec Model Failing To Train (Following Simple PyPi Tutorial)<p>I am trying to follow this tutorial on PyPi (See Example -&gt; Train Model): <a href=\\\"https://pypi.org/project/top2vec/\\\" rel=\\\"nofollow noreferrer\\\">https://pypi.org/project/top2vec/</a></p>\\n<p>Very short amount of code, following it line by line:</p>\\n<pre><code>from top2vec import Top2Vec\\nfrom sklearn.datasets import fetch_20newsgroups\\n\\nnewsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\\n\\nmodel = Top2Vec(documents=newsgroups.data, speed=&quot;learn&quot;, workers=8)\\n</code></pre>\\n<p>I've tried running multiple times on different datasets, yet I keep running into the following error when training/building the model:</p>\\n<pre><code>UFuncTypeError: ufunc 'correct_alternative_cosine' did not contain a loop with signature matching types &lt;class 'numpy.dtype[float32]'&gt; -&gt; None\\n</code></pre>\\n<p>Has anyone encountered this error before and if so how have you fixed it? Otherwise, if anyone can run this same code please let me know if you run into the same error.</p>\\n<p>Thanks</p>\",\n          \"Improve execution time with Multithreading in python<p>How can I implement multithreading to make this process faster? The program generates 1million random numbers and writes them on a file. It takes just over 2 seconds, but I'm wondering if multithreading would make it any faster.</p>\\n<pre><code>import random\\nimport time\\n\\nstartTime = time.time()\\n\\ndata = open(&quot;file2.txt&quot;, &quot;a+&quot;)\\n\\nfor i in range(1000000):\\n  number = str(random.randint(1, 9999))\\n  data.write(number + '\\\\n')\\ndata.close()\\n\\nexecutionTime = (time.time() - startTime)\\nprint('Execution time in seconds: ', + str(executionTime))\\n</code></pre>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"<p>Yeah, you're issue is a tiny quirk of the <code>random.randint()</code> function. <code>random.randint()</code> chooses a random integer between <em>and including</em> the first and second parameters that you give it, meaning that it could actually choose the second parameter that you give it as an output. Seeing that <code>len(symbols)</code> actually is not an index of symbols, you are bound to run into that <code>IndexError</code> on occasion. Each time you call <code>random.randint()</code>, subtract <code>1</code> from your second parameter and you should be good. For example:</p>\\n<pre><code>symbols_password += symbols[random.randint(0,len(symbols)-1)]\\n</code></pre>\",\n          \"<p>Solved this by moving from a Jupyter notebook in favor for a typical .py file, as well as cloning the library, installing the requirements to a fresh virtualenv and running the setup.py file.</p>\",\n          \"<p>The short answer: Not easily.</p>\\n<p>Here is an example of using a multiprocessing pool to speed up your code:</p>\\n<pre class=\\\"lang-py prettyprint-override\\\"><code>import random\\nimport time\\nfrom multiprocessing import Pool\\n\\nstartTime = time.time()\\n\\ndef f(_):\\n    number = str(random.randint(1, 9999))\\n    data.write(number + '\\\\n')\\n\\ndata = open(&quot;file2.txt&quot;, &quot;a+&quot;)\\nwith Pool() as p:\\n    p.map(f, range(1000000))\\ndata.close()\\n\\nexecutionTime = (time.time() - startTime)\\nprint(f'Execution time in seconds: {executionTime})')\\n</code></pre>\\n<p>Looks good? Wait! This is not a drop-in replacement as it lacks synchronization of the processes so not all 1000000 line will be written (some will be overwritten in the same buffer)!\\nSee <a href=\\\"https://stackoverflow.com/questions/13446445/python-multiprocessing-safely-writing-to-a-file\\\">Python multiprocessing safely writing to a file</a></p>\\n<p>So we need to separate computing the numbers (in parallel) from writing them (in serial). We can do this as follows:</p>\\n<pre class=\\\"lang-py prettyprint-override\\\"><code>import random\\nimport time\\nfrom multiprocessing import Pool\\n\\nstartTime = time.time()\\n\\ndef f(_):\\n    return str(random.randint(1, 9999))\\n\\nwith Pool() as p:\\n    output = p.map(f, range(1000000))\\n\\nwith open(&quot;file2.txt&quot;, &quot;a+&quot;) as data:\\n    data.write('\\\\n'.join(output) + '\\\\n')\\n\\nexecutionTime = (time.time() - startTime)\\nprint(f'Execution time in seconds: {executionTime})')\\n\\n</code></pre>\\n<p>With that fixed, note that this is not multithreading but uses multiple processes. You can change it to multithreading with a different pool object:</p>\\n<pre><code>from multiprocessing.pool import ThreadPool as Pool\\n</code></pre>\\n<p>On my system, I get from 1 second to 0.35 seconds with the processing pool. With the ThreadPool however it takes up to 2 seconds!</p>\\n<p>The reason is that Python's global interpreter lock prevents from multiple threads to process your task efficiently, see <a href=\\\"https://stackoverflow.com/questions/1294382/what-is-the-global-interpreter-lock-gil-in-cpython\\\">What is the global interpreter lock (GIL) in CPython?</a></p>\\n<p>To conclude, multithreading is not always the right answer:</p>\\n<ol>\\n<li>In your scenario, one limit is the file access, only one thread can write to the file, or you would need to introduce locking, making any performance gain moot</li>\\n<li>Also in Python multithreading is only suitable for specific tasks, e.g. long computations that happen in a library below python and can therefore run in parallel. In your scenario, the overhead of multithreading negates the small potential for a performance benefit.</li>\\n</ol>\\n<p>The upside: Yes, with multiprocessing instead of multithreading I got a 3x speedup on my system.</p>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adding Instructions\n",
        "I create an instruction template for the LLM"
      ],
      "metadata": {
        "id": "WlAHpV0gOZLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INSTRUCTION_TEMPLATE = f\"\"\"\\\n",
        "Please answer the following Stackoverflow question on Python. \\\n",
        "Answer it like you are a developer answering Stackoverflow questions.\n",
        "\n",
        "Stackoverflow question:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "G89NOl9JDEtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an extra column in the table for instructions"
      ],
      "metadata": {
        "id": "tDHBkMlqO18q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stack_overflow_df['input_text_instruct'] = INSTRUCTION_TEMPLATE + stack_overflow_df['input_text']\n",
        "stack_overflow_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "U2uam7sDO6j5",
        "outputId": "1e92e2e8-8d9b-4fd4-f523-d9c8abb51640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          input_text  \\\n",
              "0  Using nbconvert to hide all input cells?<p>I h...   \n",
              "1  How to multiply each digit of an array in the ...   \n",
              "2  How to get the text of the message to which th...   \n",
              "3  How to append datafrarme columns in list?<p>I ...   \n",
              "4  How to create a custom timerange and convert i...   \n",
              "\n",
              "                                         output_text  \\\n",
              "0  <p>You can pass the argument <code>--no-input<...   \n",
              "1  <p>if you want a simple solution, use numpy:</...   \n",
              "2  <p>Yes, <a href=\"https://discordpy.readthedocs...   \n",
              "3  <p>Use <a href=\"http://pandas.pydata.org/panda...   \n",
              "4  <p>You could use <code>strftime</code>:</p>\\n<...   \n",
              "\n",
              "                                 input_text_instruct  \n",
              "0  Please answer the following Stackoverflow ques...  \n",
              "1  Please answer the following Stackoverflow ques...  \n",
              "2  Please answer the following Stackoverflow ques...  \n",
              "3  Please answer the following Stackoverflow ques...  \n",
              "4  Please answer the following Stackoverflow ques...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ce593a5-4c03-4812-899b-e286f9847110\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_text</th>\n",
              "      <th>output_text</th>\n",
              "      <th>input_text_instruct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Using nbconvert to hide all input cells?&lt;p&gt;I h...</td>\n",
              "      <td>&lt;p&gt;You can pass the argument &lt;code&gt;--no-input&lt;...</td>\n",
              "      <td>Please answer the following Stackoverflow ques...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How to multiply each digit of an array in the ...</td>\n",
              "      <td>&lt;p&gt;if you want a simple solution, use numpy:&lt;/...</td>\n",
              "      <td>Please answer the following Stackoverflow ques...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How to get the text of the message to which th...</td>\n",
              "      <td>&lt;p&gt;Yes, &lt;a href=\"https://discordpy.readthedocs...</td>\n",
              "      <td>Please answer the following Stackoverflow ques...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How to append datafrarme columns in list?&lt;p&gt;I ...</td>\n",
              "      <td>&lt;p&gt;Use &lt;a href=\"http://pandas.pydata.org/panda...</td>\n",
              "      <td>Please answer the following Stackoverflow ques...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How to create a custom timerange and convert i...</td>\n",
              "      <td>&lt;p&gt;You could use &lt;code&gt;strftime&lt;/code&gt;:&lt;/p&gt;\\n&lt;...</td>\n",
              "      <td>Please answer the following Stackoverflow ques...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ce593a5-4c03-4812-899b-e286f9847110')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1ce593a5-4c03-4812-899b-e286f9847110 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1ce593a5-4c03-4812-899b-e286f9847110');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6768dcc6-6a38-4a74-ab27-62d102071370\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6768dcc6-6a38-4a74-ab27-62d102071370')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6768dcc6-6a38-4a74-ab27-62d102071370 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stack_overflow_df",
              "summary": "{\n  \"name\": \"stack_overflow_df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"input_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"why my code doesnt work? i need to make a password generator,<p>when i chose 2 letters, 2 symbols and two numbers it works, but when i chose per example 40 numbers, 40 sybmols and 40 numbers, it doesnt work, say that</p>\\n<p>when i chose 2 letters, 2 symbols and two numbers it works, but each number dont work</p>\\n<p>say that:</p>\\n<p>Traceback (most recent call last):\\nFile &quot;main.py&quot;, line 866, in \\nsymbols_password += symbols[random.randint(0,len(symbols))]\\nIndexError: list index out of range</p>\\n<p>it says that\\nthis line is line isnt on the range\\nletters[random.randint(0,len(letters))]</p>\\n<p>my code</p>\\n<pre><code>import random\\nletters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\\nnumbers = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\\nsymbols = ['!', '#', '$', '%', '&amp;', '(', ')', '*', '+']\\n\\nprint(&quot;Welcome to the PyPassword Generator!&quot;)\\nnr_letters= int(input(&quot;How many letters would you like in your password?\\\\n&quot;)) \\nnr_symbols = int(input(f&quot;How many symbols would you like?\\\\n&quot;))\\nnr_numbers = int(input(f&quot;How many numbers would you like?\\\\n&quot;))\\n\\nletters_password = &quot;&quot;\\nsymbols_password = &quot;&quot;\\nnumber_password = &quot;&quot;\\n\\nif int(nr_letters) &lt;= 50 and int(nr_symbols) &lt;= 50 and int(nr_numbers) &lt;= 50:\\n for generator_letters in range(0,int(nr_letters)):\\n   letters_password += letters[random.randint(0,len(letters))]\\n \\n for generator_symbols in range(0,int(nr_symbols)):\\n   symbols_password += symbols[random.randint(0,len(symbols))]\\n  \\n for generator_numbers in range(0,int(nr_numbers)):\\n   number_password += numbers[random.randint(0,len(numbers))]\\n\\nelse:\\n  if nr_letters &gt; 50 and nr_symbols &gt; 50 and nr_numbers &gt; 50:\\n    print(&quot;you chose too many letters,symbols and numbers.\\\\n The maximum is 50 of each&quot;)\\n  elif nr_letters &gt; 50 and nr_symbols &gt; 50  :\\n    print(&quot;you chose too many letters and symbols.\\\\n The maximun us 50 of each&quot;)\\n  elif nr_letters &gt; 50 and nr_numbers &gt; 50: \\n    print(&quot;you chose too many letters and numbers.\\\\n The maximun us 50 of each&quot;)\\n  elif nr_symbols &gt; 50 and nr_numbers &gt; 50:\\n    print(&quot;you chose too many symbols and numbers.\\\\n The maximun us 50 of each&quot;)\\n  elif nr_numbers &gt; 50:\\n    print(&quot;you chose too many numbers, the maximum is 50&quot;)\\n  elif nr_letters &gt; 50:    \\n    print(&quot;you chose too many letters, the maximum is 50&quot;)\\n  elif nr_symbols &gt; 50:\\n   print(&quot;you chose too many smybols, the maximum is 50&quot;)\\n\\n\\n\\npassword =(str(letters_password)+ str(symbols_password) + str(number_password))\\n  \\nprint(password)\\n</code></pre>\",\n          \"Top2Vec Model Failing To Train (Following Simple PyPi Tutorial)<p>I am trying to follow this tutorial on PyPi (See Example -&gt; Train Model): <a href=\\\"https://pypi.org/project/top2vec/\\\" rel=\\\"nofollow noreferrer\\\">https://pypi.org/project/top2vec/</a></p>\\n<p>Very short amount of code, following it line by line:</p>\\n<pre><code>from top2vec import Top2Vec\\nfrom sklearn.datasets import fetch_20newsgroups\\n\\nnewsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\\n\\nmodel = Top2Vec(documents=newsgroups.data, speed=&quot;learn&quot;, workers=8)\\n</code></pre>\\n<p>I've tried running multiple times on different datasets, yet I keep running into the following error when training/building the model:</p>\\n<pre><code>UFuncTypeError: ufunc 'correct_alternative_cosine' did not contain a loop with signature matching types &lt;class 'numpy.dtype[float32]'&gt; -&gt; None\\n</code></pre>\\n<p>Has anyone encountered this error before and if so how have you fixed it? Otherwise, if anyone can run this same code please let me know if you run into the same error.</p>\\n<p>Thanks</p>\",\n          \"Improve execution time with Multithreading in python<p>How can I implement multithreading to make this process faster? The program generates 1million random numbers and writes them on a file. It takes just over 2 seconds, but I'm wondering if multithreading would make it any faster.</p>\\n<pre><code>import random\\nimport time\\n\\nstartTime = time.time()\\n\\ndata = open(&quot;file2.txt&quot;, &quot;a+&quot;)\\n\\nfor i in range(1000000):\\n  number = str(random.randint(1, 9999))\\n  data.write(number + '\\\\n')\\ndata.close()\\n\\nexecutionTime = (time.time() - startTime)\\nprint('Execution time in seconds: ', + str(executionTime))\\n</code></pre>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"<p>Yeah, you're issue is a tiny quirk of the <code>random.randint()</code> function. <code>random.randint()</code> chooses a random integer between <em>and including</em> the first and second parameters that you give it, meaning that it could actually choose the second parameter that you give it as an output. Seeing that <code>len(symbols)</code> actually is not an index of symbols, you are bound to run into that <code>IndexError</code> on occasion. Each time you call <code>random.randint()</code>, subtract <code>1</code> from your second parameter and you should be good. For example:</p>\\n<pre><code>symbols_password += symbols[random.randint(0,len(symbols)-1)]\\n</code></pre>\",\n          \"<p>Solved this by moving from a Jupyter notebook in favor for a typical .py file, as well as cloning the library, installing the requirements to a fresh virtualenv and running the setup.py file.</p>\",\n          \"<p>The short answer: Not easily.</p>\\n<p>Here is an example of using a multiprocessing pool to speed up your code:</p>\\n<pre class=\\\"lang-py prettyprint-override\\\"><code>import random\\nimport time\\nfrom multiprocessing import Pool\\n\\nstartTime = time.time()\\n\\ndef f(_):\\n    number = str(random.randint(1, 9999))\\n    data.write(number + '\\\\n')\\n\\ndata = open(&quot;file2.txt&quot;, &quot;a+&quot;)\\nwith Pool() as p:\\n    p.map(f, range(1000000))\\ndata.close()\\n\\nexecutionTime = (time.time() - startTime)\\nprint(f'Execution time in seconds: {executionTime})')\\n</code></pre>\\n<p>Looks good? Wait! This is not a drop-in replacement as it lacks synchronization of the processes so not all 1000000 line will be written (some will be overwritten in the same buffer)!\\nSee <a href=\\\"https://stackoverflow.com/questions/13446445/python-multiprocessing-safely-writing-to-a-file\\\">Python multiprocessing safely writing to a file</a></p>\\n<p>So we need to separate computing the numbers (in parallel) from writing them (in serial). We can do this as follows:</p>\\n<pre class=\\\"lang-py prettyprint-override\\\"><code>import random\\nimport time\\nfrom multiprocessing import Pool\\n\\nstartTime = time.time()\\n\\ndef f(_):\\n    return str(random.randint(1, 9999))\\n\\nwith Pool() as p:\\n    output = p.map(f, range(1000000))\\n\\nwith open(&quot;file2.txt&quot;, &quot;a+&quot;) as data:\\n    data.write('\\\\n'.join(output) + '\\\\n')\\n\\nexecutionTime = (time.time() - startTime)\\nprint(f'Execution time in seconds: {executionTime})')\\n\\n</code></pre>\\n<p>With that fixed, note that this is not multithreading but uses multiple processes. You can change it to multithreading with a different pool object:</p>\\n<pre><code>from multiprocessing.pool import ThreadPool as Pool\\n</code></pre>\\n<p>On my system, I get from 1 second to 0.35 seconds with the processing pool. With the ThreadPool however it takes up to 2 seconds!</p>\\n<p>The reason is that Python's global interpreter lock prevents from multiple threads to process your task efficiently, see <a href=\\\"https://stackoverflow.com/questions/1294382/what-is-the-global-interpreter-lock-gil-in-cpython\\\">What is the global interpreter lock (GIL) in CPython?</a></p>\\n<p>To conclude, multithreading is not always the right answer:</p>\\n<ol>\\n<li>In your scenario, one limit is the file access, only one thread can write to the file, or you would need to introduce locking, making any performance gain moot</li>\\n<li>Also in Python multithreading is only suitable for specific tasks, e.g. long computations that happen in a library below python and can therefore run in parallel. In your scenario, the overhead of multithreading negates the small potential for a performance benefit.</li>\\n</ol>\\n<p>The upside: Yes, with multiprocessing instead of multithreading I got a 3x speedup on my system.</p>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_text_instruct\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\\n\\nStackoverflow question:\\nwhy my code doesnt work? i need to make a password generator,<p>when i chose 2 letters, 2 symbols and two numbers it works, but when i chose per example 40 numbers, 40 sybmols and 40 numbers, it doesnt work, say that</p>\\n<p>when i chose 2 letters, 2 symbols and two numbers it works, but each number dont work</p>\\n<p>say that:</p>\\n<p>Traceback (most recent call last):\\nFile &quot;main.py&quot;, line 866, in \\nsymbols_password += symbols[random.randint(0,len(symbols))]\\nIndexError: list index out of range</p>\\n<p>it says that\\nthis line is line isnt on the range\\nletters[random.randint(0,len(letters))]</p>\\n<p>my code</p>\\n<pre><code>import random\\nletters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\\nnumbers = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\\nsymbols = ['!', '#', '$', '%', '&amp;', '(', ')', '*', '+']\\n\\nprint(&quot;Welcome to the PyPassword Generator!&quot;)\\nnr_letters= int(input(&quot;How many letters would you like in your password?\\\\n&quot;)) \\nnr_symbols = int(input(f&quot;How many symbols would you like?\\\\n&quot;))\\nnr_numbers = int(input(f&quot;How many numbers would you like?\\\\n&quot;))\\n\\nletters_password = &quot;&quot;\\nsymbols_password = &quot;&quot;\\nnumber_password = &quot;&quot;\\n\\nif int(nr_letters) &lt;= 50 and int(nr_symbols) &lt;= 50 and int(nr_numbers) &lt;= 50:\\n for generator_letters in range(0,int(nr_letters)):\\n   letters_password += letters[random.randint(0,len(letters))]\\n \\n for generator_symbols in range(0,int(nr_symbols)):\\n   symbols_password += symbols[random.randint(0,len(symbols))]\\n  \\n for generator_numbers in range(0,int(nr_numbers)):\\n   number_password += numbers[random.randint(0,len(numbers))]\\n\\nelse:\\n  if nr_letters &gt; 50 and nr_symbols &gt; 50 and nr_numbers &gt; 50:\\n    print(&quot;you chose too many letters,symbols and numbers.\\\\n The maximum is 50 of each&quot;)\\n  elif nr_letters &gt; 50 and nr_symbols &gt; 50  :\\n    print(&quot;you chose too many letters and symbols.\\\\n The maximun us 50 of each&quot;)\\n  elif nr_letters &gt; 50 and nr_numbers &gt; 50: \\n    print(&quot;you chose too many letters and numbers.\\\\n The maximun us 50 of each&quot;)\\n  elif nr_symbols &gt; 50 and nr_numbers &gt; 50:\\n    print(&quot;you chose too many symbols and numbers.\\\\n The maximun us 50 of each&quot;)\\n  elif nr_numbers &gt; 50:\\n    print(&quot;you chose too many numbers, the maximum is 50&quot;)\\n  elif nr_letters &gt; 50:    \\n    print(&quot;you chose too many letters, the maximum is 50&quot;)\\n  elif nr_symbols &gt; 50:\\n   print(&quot;you chose too many smybols, the maximum is 50&quot;)\\n\\n\\n\\npassword =(str(letters_password)+ str(symbols_password) + str(number_password))\\n  \\nprint(password)\\n</code></pre>\",\n          \"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\\n\\nStackoverflow question:\\nTop2Vec Model Failing To Train (Following Simple PyPi Tutorial)<p>I am trying to follow this tutorial on PyPi (See Example -&gt; Train Model): <a href=\\\"https://pypi.org/project/top2vec/\\\" rel=\\\"nofollow noreferrer\\\">https://pypi.org/project/top2vec/</a></p>\\n<p>Very short amount of code, following it line by line:</p>\\n<pre><code>from top2vec import Top2Vec\\nfrom sklearn.datasets import fetch_20newsgroups\\n\\nnewsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\\n\\nmodel = Top2Vec(documents=newsgroups.data, speed=&quot;learn&quot;, workers=8)\\n</code></pre>\\n<p>I've tried running multiple times on different datasets, yet I keep running into the following error when training/building the model:</p>\\n<pre><code>UFuncTypeError: ufunc 'correct_alternative_cosine' did not contain a loop with signature matching types &lt;class 'numpy.dtype[float32]'&gt; -&gt; None\\n</code></pre>\\n<p>Has anyone encountered this error before and if so how have you fixed it? Otherwise, if anyone can run this same code please let me know if you run into the same error.</p>\\n<p>Thanks</p>\",\n          \"Please answer the following Stackoverflow question on Python. Answer it like you are a developer answering Stackoverflow questions.\\n\\nStackoverflow question:\\nImprove execution time with Multithreading in python<p>How can I implement multithreading to make this process faster? The program generates 1million random numbers and writes them on a file. It takes just over 2 seconds, but I'm wondering if multithreading would make it any faster.</p>\\n<pre><code>import random\\nimport time\\n\\nstartTime = time.time()\\n\\ndata = open(&quot;file2.txt&quot;, &quot;a+&quot;)\\n\\nfor i in range(1000000):\\n  number = str(random.randint(1, 9999))\\n  data.write(number + '\\\\n')\\ndata.close()\\n\\nexecutionTime = (time.time() - startTime)\\nprint('Execution time in seconds: ', + str(executionTime))\\n</code></pre>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset for tuning\n",
        "Now it's time to setup some evaluation set. We're not gonna calculate accuracy because I'm working with text and accuracy is very ambigous on text."
      ],
      "metadata": {
        "id": "-8PpFKtbPGOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(stack_overflow_df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "C2NZmTAjPJdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Versioning\n",
        "\n",
        "I'm creating a local versioning system using dated json files"
      ],
      "metadata": {
        "id": "sEi1rq65QQ5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "date = datetime.datetime.now().strftime(\"%Y:%m:%d:%H\")\n",
        "cols = ['input_text_instruct','output_text']\n",
        "tune_jsonl = train_df[cols].to_json(orient='records', lines=True)\n",
        "training_data_filename = f\"tune_data_stack_overflow_qa-{date}.jsonl\"\n",
        "\n",
        "with open(training_data_filename, 'w') as f:\n",
        "  f.write(tune_jsonl)"
      ],
      "metadata": {
        "id": "p_83u1P5QN0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Orchestration and Automation of a Supervised Tuning Pipeline\n",
        "The goal at this point is to train the model and evaluate it. Here I use Kubeflow Pipeline which is an open source framework to orchestrate and automate my workflow.\n",
        "\n",
        "Orchestration explains the series of steps and automation automizes this flow."
      ],
      "metadata": {
        "id": "WTfFuWX9RnUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from kfp import dsl, compiler"
      ],
      "metadata": {
        "id": "rV7HpNs1RTXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the pipeline\n",
        "Kubeflow pipelines consist of Components and pipelines. DSL (domain specific language) is the language used for designing pipelines.\n",
        "Components run in a containerized environment. We need to connect the componenets to each other. The output from one will be the input to the next one.\n",
        "\n",
        "Here we use an existing Kubeflow PipeLine for parameter-efficient fine-tuning (PEFT) from Google, called [PaLM 2](https://ai.google/discover/palm2/). Then,\n",
        "VertexAI manages the Pipeline yaml file in a serverless environment.\n",
        "\n",
        "It's quite expensive to run the following pipeline and it might take up to one day!\n",
        "\n",
        "Note: to be able to run the below code, we need to\n",
        "* Enable Vertex AI API\n",
        "* give the user this IAM role: Vertex AI Admin\n",
        "* create buckets\n",
        "\n",
        "check if the project has access to gemini fine tuning."
      ],
      "metadata": {
        "id": "C9UDi-YeS_Ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud beta ai models list --region=us-central1 --project=zeinab-llmops-vertexai-452213\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_Z6EWYLCR98",
        "outputId": "9312d52c-c4e8-44f8-a1a5-7d5af9e2a730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Listed 0 items.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the output of the above command was empty, enable Gemini tuning manually"
      ],
      "metadata": {
        "id": "yKolF57gCgpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud services enable generativelanguage.googleapis.com --project=zeinab-llmops-vertexai-452213\n",
        "\n",
        "!gcloud beta ai models list --region=us-central1 --project=zeinab-llmops-vertexai-452213\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUHLyhgzCnBS",
        "outputId": "891e5483-3163-4081-f476-9f80c77daa47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Listed 0 items.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud.aiplatform import PipelineJob\n",
        "# Define the required configurations\n",
        "MODEL_NAME = \"gemini-1.0\"  # You can specify the desired Gemini model version\n",
        "TRAINING_DATA_URI = \"gs://zeinab-llmops-vertexai/training_data.jsonl\"  # GCS URI to your training data\n",
        "EVALUATION_DATA_URI = \"gs://zeinab-llmops-vertexai/evaluation_data.jsonl\"  # GCS URI to evaluation data\n",
        "TRAINING_STEPS = 200  # Number of training steps (adjust as needed)\n",
        "EVALUATION_INTERVAL = 20  # Evaluation frequency\n",
        "\n",
        "# Get the current date for model naming\n",
        "date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "MODEL_NAME = f\"qa-model-{date}\"\n",
        "\n",
        "# Pipeline arguments\n",
        "pipeline_arguments = {\n",
        "    \"model_display_name\": MODEL_NAME,\n",
        "    \"location\": REGION,\n",
        "    \"project\": PROJECT_ID,\n",
        "    \"large_model_reference\": \"gemini-1.0-pro-002\",  # Model reference for question answering\n",
        "    # \"base_model_version_id\": \"textembedding-gecko@003\",\n",
        "    \"train_steps\": TRAINING_STEPS,\n",
        "    \"dataset_uri\": TRAINING_DATA_URI,\n",
        "    \"evaluation_interval\": EVALUATION_INTERVAL,\n",
        "    \"evaluation_data_uri\": EVALUATION_DATA_URI,\n",
        "}\n",
        "\n",
        "# Define the pipeline template path for model tuning\n",
        "template_path = \"https://us-kfp.pkg.dev/ml-pipeline/large-language-model-pipelines/tune-large-model/v2.0.0\"\n",
        "\n",
        "# Create a pipeline job for fine-tuning the model\n",
        "job = aiplatform.PipelineJob(\n",
        "    template_path=template_path,\n",
        "    display_name=\"fine-tune-gemini-qa\",\n",
        "    parameter_values=pipeline_arguments,\n",
        "    location=REGION,\n",
        "    pipeline_root=\"gs://zeinab-llmops-vertexai/pipeline_root\",  # GCS path for storing pipeline artifacts\n",
        "    enable_caching=True\n",
        ")\n",
        "\n",
        "# Submit the pipeline job\n",
        "job.submit()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "HSpYOoZ_SbMh",
        "outputId": "cd1e2a1e-2dff-4b20-d8c4-7f60e310af85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FailedPrecondition",
          "evalue": "400 Bison model tuning is deprecated. Please migrate to Gemini tuning.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    276\u001b[0m     ) -> Any:\n\u001b[0;32m--> 277\u001b[0;31m         response, ignored_call = self._with_call(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m_with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;34m\"\"\"See grpc.Future.result.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36mcontinuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 response, call = self._thunk(new_method).with_call(\n\u001b[0m\u001b[1;32m    316\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mwith_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1197\u001b[0m         )\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.FAILED_PRECONDITION\n\tdetails = \"Bison model tuning is deprecated. Please migrate to Gemini tuning.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:172.217.203.95:443 {created_time:\"2025-02-28T06:30:14.731451386+00:00\", grpc_status:9, grpc_message:\"Bison model tuning is deprecated. Please migrate to Gemini tuning.\"}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mFailedPrecondition\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-88f79bb795fb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Submit the pipeline job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, service_account, network, reserved_ip_ranges, create_request_timeout, experiment, enable_preflight_validations)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             self._gca_resource = self.api_client.create_pipeline_job(\n\u001b[0m\u001b[1;32m    513\u001b[0m                 \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0mpipeline_job\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/aiplatform_v1/services/pipeline_service/client.py\u001b[0m in \u001b[0;36mcreate_pipeline_job\u001b[0;34m(self, request, parent, pipeline_job, pipeline_job_id, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   1648\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPrecondition\u001b[0m: 400 Bison model tuning is deprecated. Please migrate to Gemini tuning."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions, Prompts and Safety\n",
        "Now that we've obtained the trained model, we want to use it. Here we have to choices, either Batch or REST API. The latter was used in the pipeline.\n",
        "\n",
        "REST API deploys the model as an api and accesses it like a server. So this is online as opposed to the batch method which is done offline. For REST API therefore, we need low latency. With FAST API or FLASK we can deploy a model as an API and package it in a container. Then we call the model and get a prediction."
      ],
      "metadata": {
        "id": "YbRAKMISgSfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.language_models import TextGenerationModel"
      ],
      "metadata": {
        "id": "cCX9w0Iwd79i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "list_tuned_models = model.list_tuned_model_names()\n",
        "\n",
        "for i in list_tuned_models:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "kx9h56O2gcIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see above that we have three instaces of the model, so we can distribute the load between them."
      ],
      "metadata": {
        "id": "VA_cp_1shqQf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xIShg3Rmhnlq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}